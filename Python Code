import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import string
import spacy
from spacy.lang.en.stop_words import STOP_WORDS
from sklearn.svm import LinearSVC
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Load data
def load_data():
    column_name = ['Review', 'Sentiment']
    
    data_yelp = pd.read_csv("/content/yelp_labelled.txt", sep='\t', header=None, names=column_name)
    data_amazon = pd.read_csv("/content/amazon_cells_labelled.txt", sep='\t', header=None, names=column_name)
    data_imdb = pd.read_csv("/content/imdb_labelled.txt", sep='\t', header=None, names=column_name)
    
    return pd.concat([data_yelp, data_amazon, data_imdb], ignore_index=True)

data = load_data()

# Text Cleaning
nlp = spacy.load("en_core_web_sm")
punct = string.punctuation
stopwords = STOP_WORDS

def text_data_cleaning(sentence):
    doc = nlp(sentence)
    tokens = [token.lemma_.lower().strip() if token.lemma_ != "-PRON-" else token.lower_ for token in doc]
    cleaned_tokens = [token for token in tokens if token not in stopwords and token not in punct]
    return cleaned_tokens

# Train-test split
x_train, x_test, y_train, y_test = train_test_split(data['Review'], data['Sentiment'], test_size=0.2, random_state=0)

# Model Pipeline
tfidf = TfidfVectorizer(tokenizer=text_data_cleaning)
classifier = LinearSVC()
clf = Pipeline([('tfidf', tfidf), ('clf', classifier)])

# Train Model
clf.fit(x_train, y_train)

# Evaluate Model
y_pred = clf.predict(x_test)
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
print("Accuracy Score:", accuracy_score(y_test, y_pred))

# Predictions
print(clf.predict(["This product is not useful."]))
print(clf.predict(["I loved it. It is very good."]))
